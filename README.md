<p align="center">
  <img src="assets/architecture.avif" alt="Human vs AI Concept" width="800">
</p>



# ğŸ§  AI Detector â€“ Hybrid BERT & Stylometric Analysis

## ğŸ“Œ Overview
Questo progetto implementa un **sistema end-to-end per il rilevamento di testi generati da Intelligenza Artificiale**, combinando modelli NLP moderni e tecniche di analisi stilometrica.  
L'obiettivo Ã¨ distinguere testi **scritti da esseri umani** da testi **generati da modelli AI**, adottando un approccio sia **predittivo** sia **interpretabile**.

Il sistema Ã¨ stato progettato come applicazione **full-stack containerizzata**, includendo backend AI, frontend web e orchestrazione tramite Docker.

---

<p align="center">
  <img src="assets/ai_ex.gif" width="380"/>
  <img src="assets/hum.gif" width="380"/>
</p>


## ğŸ—ï¸ Architettura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  REST API  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React UI  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  FastAPI ML  â”‚
â”‚  Frontend  â”‚            â”‚   Backend    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Modelli ML   â”‚
                         â”‚  BERT (.pth)   â”‚
                         â”‚ Signature(.pkl)â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Frontend**: React + TailwindCSS  
- **Backend**: Python + FastAPI  
- **Modelli**: BERT + feature stilometriche  
- **Deployment**: Docker & Docker Compose  

---

## ğŸ“ Struttura del Progetto

```
bert_ai_detector/
â”‚
â”œâ”€â”€ app.py                  # Backend FastAPI
â”œâ”€â”€ requirements.txt        # Dipendenze Python
â”œâ”€â”€ Dockerfile              # Backend container
â”‚
â”œâ”€â”€ react-app/              # Frontend React
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â””â”€â”€ AIDetectorInterface.jsx
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ pth/                    # Modelli deep learning
â”‚   â””â”€â”€ best_bert.pth
â”‚
â”œâ”€â”€ pkl/                    # Modelli ML / signature
â”œâ”€â”€ txt/                    # File di supporto
â”‚
â”œâ”€â”€ *.ipynb                 # Notebook (EDA, training, analisi)
â”œâ”€â”€ *.csv                   # Dataset
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

I notebook Jupyter sono volutamente esclusi dai container per separare la fase di **training** da quella di **inference**.

---

## ğŸ”¬ Metodologia

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)
- Analisi statistica dei testi AI vs Human
- Studio di lunghezza, variabilitÃ  e struttura
- Supporto alle decisioni di feature engineering

### 2ï¸âƒ£ Signature Stilometriche
- DiversitÃ  lessicale
- RipetitivitÃ  strutturale
- Burstiness
- Lunghezza media delle frasi

Queste feature forniscono un livello di **interpretabilitÃ ** complementare ai modelli deep learning.

### 3ï¸âƒ£ Modello Ibrido (BERT + Feature Stilometriche)
- Embedding contestuali ottenuti tramite BERT
- Integrazione con feature linguistiche manuali
- Migliore robustezza e generalizzazione rispetto ad approcci singoli

---

## ğŸ“Š Risultati

| Architettura              | Accuracy (Test) | Punti di forza |
|--------------------------|----------------|---------------|
| **Hybrid (BERT + Style)** | **97.83%**     | Unisce contesto semantico e impronta stilistica |
| LSTM (Recurrent)         | 97.03%         | Cattura dipendenze sequenziali |
| BERT Fine-tuned          | 96.75%         | Comprensione semantica profonda |
| CNN (Convolutional)      | 92.50%         | Ottimo nel rilevare pattern locali (n-gram) |
| Baseline (Style Only)    | 86.72%         | Interpretazione delle abitudini di scrittura |


## âš™ï¸ Backend â€“ FastAPI

Il backend espone un'API REST per l'analisi dei testi.

### Endpoint
`POST /analyze`

### Input
```json
{
  "text": "Testo da analizzare"
}
```

### Output
```json
{
  "isAI": true,
  "confidence": 87.3,
  "metrics": {
    "lexical_diversity": 0.42,
    "burstiness": 3.1,
    "avg_sentence_length": 18.7
  }
}
```

---

## ğŸ¨ Frontend â€“ React App

Il frontend fornisce un'interfaccia web interattiva per:

- Inserimento del testo
- Validazione dell'input
- Visualizzazione dei risultati e delle metriche
- Comunicazione diretta con il backend tramite REST API

---

## ğŸ³ Containerizzazione con Docker

Il sistema Ã¨ completamente containerizzato tramite Docker Compose, che orchestra:

- Backend AI (FastAPI + modelli ML)
- Frontend React

### Avvio del progetto
```bash
docker-compose build
docker-compose up
```

| Servizio | | Descrizione     |
|----------| |-----------------|
| Backend  | | API AI Detector |
| Frontend | | Interfaccia Web |

La comunicazione tra frontend e backend avviene tramite service name Docker, garantendo portabilitÃ  e riproducibilitÃ .

---

## ğŸ“ Scelte Progettuali

- **Separazione tra training e inference**
- **Approccio ibrido** per bilanciare performance e interpretabilitÃ 
- **Containerizzazione** per:
  - RiproducibilitÃ  degli esperimenti
  - Isolamento dell'ambiente
  - SemplicitÃ  di deploy
- **Interfaccia grafica** come strumento di analisi e non solo demo

---
## ğŸ—„ï¸ Persistenza dei Dati con SQLite3

<p align="center">
  <img src="assets/tab_pred.png" width="800">
  <img src="assets/tab_seq.png" width="400">
</p>



Per completare il sistema di AI Detection, non ci siamo limitati alla sola predizione in tempo reale, ma abbiamo introdotto un livello di **persistenza dei dati**, fondamentale per garantire tracciabilitÃ , analisi e validazione dei risultati.

A questo scopo Ã¨ stato utilizzato **SQLite3**, un database relazionale embedded, leggero e privo di dipendenze esterne.

---

### ğŸ¯ PerchÃ© SQLite3

SQLite3 Ã¨ particolarmente adatto a questo tipo di progetto per diversi motivi:

- Non richiede un server dedicato
- Ãˆ immediatamente integrabile in applicazioni Python
- Funziona tramite un singolo file `.db`
- Ãˆ ideale per ambienti containerizzati
- Garantisce semplicitÃ , portabilitÃ  e affidabilitÃ 

Essendo il progetto di natura accademica e orientato allâ€™analisi, SQLite rappresenta una scelta progettuale equilibrata tra semplicitÃ  ed efficacia.

---



### ğŸ§  Ruolo del Database nel Sistema

Il database non influisce sul processo decisionale del modello, ma svolge un ruolo chiave nel **monitoraggio delle predizioni**.

In particolare, consente di:

- Salvare ogni predizione effettuata dal sistema
- Conservare informazioni su confidenza e modello utilizzato
- Analizzare il comportamento del detector nel tempo
- Supportare future estensioni (dashboard, statistiche, auditing)

Ogni chiamata allâ€™endpoint `/predict` genera automaticamente una nuova entry nel database.

---

### ğŸ§± Struttura del Database

Il database contiene una singola tabella chiamata `predictions`, progettata per essere semplice ma estendibile.

I campi principali includono:
- Un identificatore univoco
- Timestamp della predizione
- Etichetta finale (AI o Human)
- Confidenza associata
- Metriche stilometriche
- Versione del modello utilizzato

Questa struttura permette di mantenere uno storico completo delle analisi.

---

### âš™ï¸ Inizializzazione Automatica

Il database viene inizializzato automaticamente allâ€™avvio dellâ€™applicazione backend.

Se la tabella esiste giÃ , il sistema lo rileva e non interviene.
Se la tabella non esiste, viene creata automaticamente.

Questo approccio garantisce:
- Robustezza
- Assenza di configurazioni manuali
- CompatibilitÃ  con Docker e deploy automatico

---

### ğŸ” Integrazione con il Backend

Dal punto di vista architetturale, la gestione del database Ã¨ isolata nel file `db.py`.

Il backend **FastAPI**:
1. Riceve il testo dallâ€™utente
2. Esegue la predizione tramite il modello AI
3. Restituisce il risultato al frontend
4. Salva automaticamente i dati nel database

Il salvataggio Ã¨ completamente trasparente per lâ€™utente finale.

---

### ğŸ” Ispezione e Debug

Il file del database puÃ² essere aperto tramite strumenti grafici come **DB Browser for SQLite**, consentendo:

- Verifica immediata dei record
- Controllo della correttezza delle predizioni
- Analisi manuale dei risultati

Questo Ã¨ particolarmente utile in fase di testing e validazione del sistema.

---

### ğŸ§© Estensioni Future

Lâ€™introduzione di SQLite apre la strada a possibili sviluppi futuri, tra cui:

- Analisi statistiche delle predizioni
- Dashboard di monitoraggio
- Migrazione verso database piÃ¹ complessi (PostgreSQL)
- Logging avanzato e audit trail

In questo modo, il sistema non Ã¨ solo un detector, ma una piattaforma analizzabile e tracciabile.

---



Lâ€™integrazione di SQLite3 completa il progetto dal punto di vista ingegneristico, trasformando il modello AI in un sistema reale e persistente.

La scelta di un database embedded riflette una progettazione consapevole, orientata alla semplicitÃ , alla riproducibilitÃ  e alla qualitÃ  del software.



## âš ï¸ Limiti e Sviluppi Futuri

- Generalizzazione rispetto a modelli AI futuri
- Integrazione del supporto GPU (CUDA)
- Valutazione cross-domain
- Logging e monitoring delle predizioni
- Supporto per analisi batch

---

## ğŸ‘¤ Autore

Progetto sviluppato come lavoro accademico nell'ambito di Machine Learning e Natural Language Processing.

---

## ğŸ Conclusione

Il progetto dimostra come sia possibile costruire un AI Detector moderno e completo, combinando:

- Analisi statistica
- Modelli deep learning
- InterpretabilitÃ  linguistica
- Ingegneria del software

Il risultato Ã¨ un sistema modulare, riproducibile e pronto al deploy.